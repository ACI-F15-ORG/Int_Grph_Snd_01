My original idea and what I ended up with are very different.  I’ll breakdown what I ended up with and then touch on what I tried to do (but couldn’t figure out).  For my project I wanted there to be some kind of physical input from the viewer.  I settled on using an arduino and two flex sensors to control the sketch.  The flex sensors would send their position to OF and that data would then be mapped to the size of the sketch window and translated into X and Y values.  The user could then control a ribbon that flies across the screen.  Depending on the position of the ribbon the program played various notes in the pentatonic scale and attempts to harmonize with itself.  What I originally wanted  (and was ultimately unable to do) was for the path/shape that the user draws with the ribbon to be directly translated into a waveform that the program would then attempt to play.  The sound would be constantly evolving via the user input.